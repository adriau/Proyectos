{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# REDES NEURONALES\n",
    "\n",
    "Una red neuronal es un modelo simplificado que emula el modo en que el cerebro humano procesa la información: Funciona simultaneando un número elevado de unidades de procesamiento interconectadas que parecen versiones abstractas de neuronas. Modelos que están compuestos de múltiples capas de procesamiento para aprender representaciones de datos, con múltiples niveles de abstracción que realizan una serie de transformaciones lineales y no lineales que a partir de los datos de entrada generen una salida próxima a la esperada (label).\n",
    "\n",
    "Las unidades de procesamiento se organizan en capas. Hay tres partes normalmente en una red neuronal :\n",
    "* una capa de entrada, con unidades que representan los campos de entrada.\n",
    "* Una o varias capas ocultas.\n",
    "* Una capa de salida, con una unidad o unidades que representa el campo o los campos de destino.\n",
    "Las unidades se conectan con fuerzas de conexión variables (o ponderaciones). Los datos de entrada se presentan en la primera capa, y los valores se propagan desde cada neurona hasta cada neurona de la capa siguiente. al final, se envía un resultado desde la capa de salida.\n",
    "\n",
    "La red aprende examinando los registros individuales, generando una predicción para cada registro y realizando ajustes a las ponderaciones cuando realiza una predicción incorrecta. Este proceso se repite muchas veces y la red sigue mejorando sus predicciones hasta haber alcanzado uno o varios criterios de parada.\n",
    "\n",
    "<img src=\"img/3.jpg\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algoritmos de regresión\n",
    "Los algoritmos de regresión modelan la relación entre distintas variables de entrada (features) utilizando una medida de error, la loss, que se intentará minimizar en un proceso iterativo para poder realizar predicciones “lo más acertadas posibles”. Hablaremos de dos tipos: regresión logística y regresión lineal.\n",
    "\n",
    "La diferencia principal entre regresión logística y lineal es en el tipo de salida de los modelos; cuando nuestra salida sea discreta, hablamos de regresión logística, y cuando la salida sea continua hablamos de regresión lineal. La regresión logística es un algoritmo con aprendizaje supervisado y se utiliza para clasificar."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Funciones de activación\n",
    "La función de activación devuelve una salida que será generada por la neurona dada una entrada o conjunto de entradas. Cada una de las capas que conforman la red neuronal tienen una función de activación que permitirá reconstruir o predecir. Además, se debe considerar que en la red neuronal se usará una función no lineal debido a que le permite al modelo adaptarse para trabajar con la mayor cantidad de datos. Las funciones de activación no son más que la manera de trasmitir esta información por las conexiones de salida. Las funciones de activación se utilizan para dar una «no linealidad» al modelo y que la red sea capaz de resolver problemas más complejos. Si todas las funciones de activación fueran lineales, la red resultante sería equivalente a una red sin capas ocultas.\n",
    "\n",
    "* **Función lineal**: Esta función también conocida como identidad, permite que lo de la entrada sea igual a la salida por lo que si tengo un red neuronal de varias capas y aplicó función lineal se dice que es una regresión lineal. Por lo tanto, **esta función de activación lineal se usa si a la salida se requiere una regresión lineal y de esta manera a la red neuronal que se le aplica la función va a generar un valor único**. Por ejemplo se usa cuando se solicita predecir el valor de un número de ventas.\n",
    "                                            <img src=\"img/lineal.png\" height=300>\n",
    "* **Función escalón**: Indica que si la x es menor que cero la neurona va a ser cero pero cuando es mayor igual a cero dará como salida igual 1. **Esta función se usa cuando se quiere clasificar o cuando se tiene salidas categóricas**.\n",
    "                                            <img src=\"img/escalon.png\" height=300>\n",
    "* **Función sigmoide**: Esta función también conocida como función logística, está en un rango de valores de salida entre cero y uno por lo que la salida es interpretada como una probabilidad. Si se evalúa la función con valores de entrada muy negativos, es decir x<0 la función será igual a cero, si se evalúa en cero la función dará 0.5 y en valores altos su valor es aproximadamente a 1. **Por lo que esta función se usa en la última capa y se usa para clasificar datos en dos categorías**. Actualmente la sigmoide no es una función muy utilizada debido a que no está centrada y esto afecta en el aprendizaje y entrenamiento de la neurona por lo que influye con el problema de desaparición de gradiente. Cuanto más positivo es el valor de x más nos acercamos a 1 y por el contrario, cuanto más negativo es x más nos acercamos a 0. Existe una división entre los valores negativos y positivos de x, pero la función sigmoide no es tan estricta, el cambio se hace de manera suave. La función no tiene aristas, es más suave. **Se usa en la regresión logística, una de las técnicas más usadas en Machine Learning. Esta función es muy útil en la capa final de salida al final de la red neuronal, no solo para clasificar con valores categóricos, sino también para intentar predecir las probabilidades de pertenencia a cada categoría, donde sabemos que la probabilidad de un suceso imposible es 0 y la de un suceso seguro es 1**.\n",
    "                                            <img src=\"img/sigmoide.png\" height=300>\n",
    "* **Función rectificadora** (ReLU): Está función es la más utilizada debido a que permite el aprendizaje muy rápido en las redes neuronales. Si a esta función se le da valores de entrada muy negativos el resultado es cero pero si se le da valores positivos queda igual y además el gradiente de esta función será cero en el segundo cuadrante y uno en el primer cuadrante. Cuando se tiene que la función es igual a cero y su derivada también se genera lo que es la muerte de neuronas, a pesar que puede ser un inconveniente en algunos casos permite la regularización Dropout. Por esta razón la función ReLu tiene una variante denominada Leaky ReLu que va a prevenir que existan neuronas muertas debido a la pequeña pendiente que existe cuando x<0.\n",
    "                                            <img src=\"img/relu.png\" height=300>\n",
    "* **Función tangente hiperbólico**: Esta función de activación llamada tangente hiperbólica tiene un rango de valores de salida entre -1 y 1. Se dice que está función es un escalamiento de la función logística, por lo que a pesar que esta función está centrada tiene un problema similar a la sigmoide debido al problema de desaparición del gradiente, que se da cuando en el entrenamiento se genera un error con el algoritmo de propagación hacia atrás y debido a esto el error se va propagando entre las capas, por lo que en cada iteración toma un valor pequeño y la red no puede obtener un buen aprendizaje. No empieza en 0 y termina en 1, sino que empieza en -1 y termina en 1.\n",
    "                                            <img src=\"img/tang.png\" height=300>\n",
    "* **Función softmax**: **Esta función se usa para clasificar datos**, por ejemplo si le damos de entrada la imagen de una fruta y se solicita saber el tipo de fruta a que pertenece, aplicando softmax la red nos dará la probabilidad de que puede ser 0.3 o 30% melón, 0.2 o 20% sandía y 0.5 o 50% papaya, por lo que nos da el resultado será el que tenga mayor probabilidad y cabe recalcar que la suma de estas probabilidades será igual a 1. En otras palabras, **Softmax se usa para clases múltiples y cuando se va a asignar probabilidades a cada clase que pertenezca a clases múltiples**.\n",
    "                                            <img src=\"img/softmax.png\" height=300>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "data = np.random.random((1000,100))\n",
    "labels = np.random.randint(2,size=(1000,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La clase Sequential de la librería de Keras es una envoltura para el modelo de red neuronal secuencial que ofrece Keras. En este caso, el modelo en Keras se considera como una secuencia de capas que cada una de ellas va “destilando” gradualmente los datos de entrada para obtener la salida deseada."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model = Sequential() # Creamos un modelo secuencia y agregaremos capas una a una hasta que cumplan nuestros requerimientos."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "la red neuronal se ha definido como una secuencia de dos capas que están densamente conectadas, es decir, que todas las neuronas de cada capa están conectadas con todas las neuronas de la capa siguiente."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# La primera capa debe tener el numero correcto de entradas, esto se puede especificar con el argumento input_dim. El numero de neuronas de entrada esta determinado por el numero de variables de entrada (columnas).\n",
    "# La capa de salida, si por ejemplo estamos resolviendo un problema de clasificación tendra un numero de neuronas igual al numero de clases que existan en los datos.\n",
    "\n",
    "# Capas completamente conectadas son definidas mediante la clase Dense.\n",
    "# En la clase Dense se especifica: el numero de neuronas, la función de inicialización y la función de activación.\n",
    "# input_dim indica el numero de neuronas que contiene la capa de entrada.\n",
    "model.add(Dense(32, activation='relu', input_dim=100)) # 32 indica el número de neuronas\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,265\n",
      "Trainable params: 3,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # método muy útil para comprobar la arquitectura de nuestra modelo."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compilar el modelo\n",
    "Una vez que tengamos nuestro modelo definido, podemos configurar cómo será su proceso de aprendizaje con el método compile( ), con el que podemos especificar algunas propiedades a través de argumentos del método.\n",
    "El primero de estos argumentos es la función de loss que usaremos para evaluar el grado de error entre salidas calculadas y las salidas deseadas de los datos de entrenamiento.\n",
    "Se especifica un optimizador que, como veremos, es la manera que tenemos de especificar el algoritmo de optimitzaación que permite a la red neuronal calcular los pesos de los parámetros a partir de los datos de entrada y de la función de loss definida.\n",
    "Debemos indicar la métrica que usaremos para monitorizar el proceso de aprendizaje (y prueba) de nuestra red neuronal."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compilamos el modelo. loss es la función de perdida que sirve para evaluar los pesos (binary-crossentropy es una función logarítmica de perdida), el otimizador utilizado para buscar entre los pesos de la red\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.7151 - accuracy: 0.5050\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.5200\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5270\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5470\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5710\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5700\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5820\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.5960\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6717 - accuracy: 0.5730\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6641 - accuracy: 0.6060\n"
     ]
    }
   ],
   "source": [
    "model.fit(data,labels,epochs=10,batch_size=32)\n",
    "predictions = model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n",
      "65536/57026 [==================================] - 0s 0us/step\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 7s 0us/step\n",
      "170508288/170498071 [==============================] - 7s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "17473536/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing, mnist, cifar10, imdb\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "(x_train2,y_train2),(x_test2,y_test2) = boston_housing.load_data()\n",
    "(x_train3,y_train3),(x_test3,y_test3) = cifar10.load_data()\n",
    "(x_train4,y_train4),(x_test4,y_test4) = imdb.load_data(num_words=20000)\n",
    "num_classes = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "model2 = Sequential()\n",
    "model3 = Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funciones de activación\n",
    "* **relu** (Rectified Linear): Si el valor de mi x < 0, devuelve 0. Si no devuelve x.\n",
    "* Tanh: Igual que sigmoid pero entre -1 y 1.\n",
    "* **sigmoid** (Logistic): Para x muy grande nos da 1, si es muy pequeño nos da 0. Entre 0 y 1\n",
    "* softmax: Devuelve la probabilidad de que sea de un tipo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Binary Classification\n",
    "from keras.layers import Dense\n",
    "model.add(Dense(12,input_dim=8,kernel_initializer='uniform',activation='relu'))\n",
    "model.add(Dense(8,kernel_initializer='uniform',activation='relu'))\n",
    "model.add(Dense(1,kernel_initializer='uniform',activation='sigmoid'))\n",
    "\n",
    "#Multi-Class Classification\n",
    "from keras.layers import Dropout\n",
    "model.add(Dense(512,activation='relu',input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "#Regression\n",
    "model.add(Dense(64,activation='relu',input_dim=x_train.shape[1]))\n",
    "model.add(Dense(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}